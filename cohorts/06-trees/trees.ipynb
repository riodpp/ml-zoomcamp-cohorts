{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-31 22:10:20--  https://github.com/alexeygrigorev/datasets/raw/refs/heads/master/jamb_exam_results.csv\n",
      "Resolving github.com (github.com)... 64:ff9b::14cd:f3a6, 20.205.243.166\n",
      "Connecting to github.com (github.com)|64:ff9b::14cd:f3a6|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/alexeygrigorev/datasets/refs/heads/master/jamb_exam_results.csv [following]\n",
      "--2024-10-31 22:10:20--  https://raw.githubusercontent.com/alexeygrigorev/datasets/refs/heads/master/jamb_exam_results.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 64:ff9b::b9c7:6c85, 64:ff9b::b9c7:6e85, 64:ff9b::b9c7:6f85, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|64:ff9b::b9c7:6c85|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 391501 (382K) [text/plain]\n",
      "Saving to: ‘jamb_exam_results.csv’\n",
      "\n",
      "jamb_exam_results.c 100%[===================>] 382.33K  90.1KB/s    in 4.2s    \n",
      "\n",
      "2024-10-31 22:10:26 (90.1 KB/s) - ‘jamb_exam_results.csv’ saved [391501/391501]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/alexeygrigorev/datasets/raw/refs/heads/master/jamb_exam_results.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jamb_score</th>\n",
       "      <th>study_hours_per_week</th>\n",
       "      <th>attendance_rate</th>\n",
       "      <th>teacher_quality</th>\n",
       "      <th>distance_to_school</th>\n",
       "      <th>school_type</th>\n",
       "      <th>school_location</th>\n",
       "      <th>extra_tutorials</th>\n",
       "      <th>access_to_learning_materials</th>\n",
       "      <th>parent_involvement</th>\n",
       "      <th>it_knowledge</th>\n",
       "      <th>student_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>socioeconomic_status</th>\n",
       "      <th>parent_education_level</th>\n",
       "      <th>assignments_completed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>22</td>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>12.4</td>\n",
       "      <td>Public</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>Male</td>\n",
       "      <td>Low</td>\n",
       "      <td>Tertiary</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>207</td>\n",
       "      <td>14</td>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>Public</td>\n",
       "      <td>Rural</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>Male</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182</td>\n",
       "      <td>29</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>Public</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>Female</td>\n",
       "      <td>High</td>\n",
       "      <td>Tertiary</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210</td>\n",
       "      <td>29</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>Public</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>High</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>Female</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tertiary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199</td>\n",
       "      <td>12</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>8.8</td>\n",
       "      <td>Public</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>Female</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tertiary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   jamb_score  study_hours_per_week  attendance_rate  teacher_quality  \\\n",
       "0         192                    22               78                4   \n",
       "1         207                    14               88                4   \n",
       "2         182                    29               87                2   \n",
       "3         210                    29               99                2   \n",
       "4         199                    12               98                3   \n",
       "\n",
       "   distance_to_school school_type school_location extra_tutorials  \\\n",
       "0                12.4      Public           Urban             Yes   \n",
       "1                 2.7      Public           Rural              No   \n",
       "2                 9.6      Public           Rural             Yes   \n",
       "3                 2.6      Public           Urban              No   \n",
       "4                 8.8      Public           Urban              No   \n",
       "\n",
       "  access_to_learning_materials parent_involvement it_knowledge  student_id  \\\n",
       "0                          Yes               High       Medium           1   \n",
       "1                          Yes               High         High           2   \n",
       "2                          Yes               High       Medium           3   \n",
       "3                          Yes             Medium         High           4   \n",
       "4                          Yes             Medium       Medium           5   \n",
       "\n",
       "   age  gender socioeconomic_status parent_education_level  \\\n",
       "0   17    Male                  Low               Tertiary   \n",
       "1   15    Male                 High                    NaN   \n",
       "2   20  Female                 High               Tertiary   \n",
       "3   22  Female               Medium               Tertiary   \n",
       "4   22  Female               Medium               Tertiary   \n",
       "\n",
       "   assignments_completed  \n",
       "0                      2  \n",
       "1                      1  \n",
       "2                      2  \n",
       "3                      1  \n",
       "4                      1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('jamb_exam_results.csv')\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "- Remove the student_id column.\n",
    "- Fill missing values with zeros.\n",
    "- Do train/validation/test split with 60%/20%/20% distribution.\n",
    "- Use the train_test_split function and set the random_state parameter to 1.\n",
    "- Use DictVectorizer(sparse=True) to turn the dataframes into matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['student_id'])\n",
    "\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.98360662, 5.44673737, 5.08759634, ..., 5.37989735, 5.45958551,\n",
       "       4.6443909 ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = np.log1p(df_train.jamb_score.values)\n",
    "y_val = np.log1p(df_val.jamb_score.values)\n",
    "y_test = np.log1p(df_test.jamb_score.values)\n",
    "\n",
    "# df_train = df_train.drop(columns=['assignments_completed'])\n",
    "# df_val = df_val.drop(columns=['assignments_completed'])\n",
    "# df_test = df_test.drop(columns=['assignments_completed'])\n",
    "\n",
    "# dv = DictVectorizer(sparse=True)\n",
    "\n",
    "# X_train = dv.fit_transform(df_train.to_dict(orient='records'))\n",
    "# X_val = dv.transform(df_val.to_dict(orient='records'))\n",
    "# X_test = dv.transform(df_test.to_dict(orient='records'))\n",
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3000, 29)\n",
      "X_val shape: (1000, 29)\n",
      "X_test shape: (1000, 29)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_val shape: {X_val.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Let's train a decision tree regressor to predict the jamb_score variable.\n",
    "\n",
    "Train a model with max_depth=1.\n",
    "Which feature is used for splitting the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- study_hours_per_week <= 19.50\n",
      "|   |--- class: 1\n",
      "|--- study_hours_per_week >  19.50\n",
      "|   |--- class: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(export_text(model, feature_names=dv.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1, 3, 1, 3, 1, 1, 4, 4, 2, 1, 1, 1, 1, 3, 1, 2, 1, 1, 2,\n",
       "       1, 2, 4, 2, 1, 2, 1, 1, 1, 2, 1, 3, 4, 1, 1, 1, 1, 1, 3, 1, 2, 3,\n",
       "       1, 2, 3, 1, 2, 1, 1, 3, 1, 3, 3, 4, 1, 2, 2, 1, 3, 1, 1, 1, 2, 1,\n",
       "       2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 3, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1,\n",
       "       1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 3, 3, 3, 1, 3, 1, 1, 3, 1,\n",
       "       1, 1, 3, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 3, 2, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 3, 1, 2, 3, 3, 1, 2, 2, 2, 3, 1, 1, 1, 3, 3, 1, 1,\n",
       "       1, 3, 2, 2, 2, 1, 3, 1, 2, 1, 1, 2, 2, 1, 1, 3, 2, 1, 2, 2, 3, 1,\n",
       "       2, 1, 2, 2, 1, 5, 3, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1,\n",
       "       1, 3, 1, 2, 2, 2, 1, 4, 1, 1, 1, 1, 4, 3, 3, 1, 1, 3, 3, 3, 1, 1,\n",
       "       2, 3, 1, 5, 2, 3, 1, 1, 3, 2, 1, 2, 1, 3, 1, 1, 2, 2, 3, 1, 4, 2,\n",
       "       1, 2, 4, 1, 1, 2, 2, 1, 3, 1, 2, 1, 1, 1, 1, 3, 1, 2, 3, 1, 4, 3,\n",
       "       2, 1, 3, 2, 1, 3, 5, 2, 1, 1, 1, 3, 1, 2, 2, 4, 1, 2, 1, 1, 1, 3,\n",
       "       2, 1, 5, 5, 1, 2, 4, 2, 1, 2, 2, 1, 4, 3, 1, 1, 3, 1, 2, 3, 2, 2,\n",
       "       2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 3, 1, 2, 1, 2, 1, 2, 2, 1,\n",
       "       2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 3, 1, 5, 3, 1, 1, 1, 2, 1, 3, 3,\n",
       "       3, 1, 2, 2, 2, 1, 2, 3, 1, 2, 2, 4, 1, 1, 3, 1, 1, 4, 2, 5, 1, 1,\n",
       "       1, 1, 1, 3, 2, 4, 2, 2, 1, 4, 1, 1, 3, 1, 5, 1, 3, 1, 2, 1, 1, 1,\n",
       "       1, 3, 2, 3, 1, 2, 1, 2, 2, 4, 1, 3, 2, 3, 2, 2, 2, 1, 1, 1, 1, 1,\n",
       "       4, 1, 1, 1, 2, 1, 3, 3, 1, 5, 2, 1, 1, 2, 2, 2, 1, 2, 3, 1, 2, 1,\n",
       "       2, 4, 4, 1, 1, 2, 3, 1, 3, 1, 2, 1, 4, 1, 1, 1, 1, 1, 1, 2, 2, 1,\n",
       "       2, 2, 2, 1, 1, 4, 4, 3, 1, 1, 3, 3, 2, 2, 3, 1, 2, 2, 2, 3, 1, 1,\n",
       "       1, 5, 1, 1, 1, 1, 2, 2, 1, 1, 4, 2, 1, 3, 2, 2, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1, 2, 1, 2, 4, 3, 1, 1, 1, 1, 1, 2, 1, 1, 2, 3, 1, 1, 1, 4, 1,\n",
       "       1, 4, 3, 1, 1, 1, 1, 1, 1, 1, 2, 3, 2, 1, 1, 1, 1, 1, 2, 3, 1, 1,\n",
       "       4, 4, 3, 1, 4, 2, 1, 3, 1, 2, 3, 1, 1, 3, 1, 1, 1, 2, 2, 1, 1, 2,\n",
       "       4, 2, 1, 1, 1, 1, 1, 2, 4, 1, 2, 3, 1, 4, 2, 2, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1, 4, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 1, 1, 2, 2, 1, 1, 3, 1,\n",
       "       2, 4, 1, 1, 1, 4, 1, 3, 2, 2, 1, 4, 1, 3, 2, 1, 4, 2, 1, 1, 1, 1,\n",
       "       1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       3, 1, 1, 1, 1, 1, 2, 1, 2, 3, 2, 1, 4, 1, 1, 2, 2, 1, 1, 1, 1, 1,\n",
       "       3, 1, 1, 1, 2, 5, 4, 2, 2, 1, 2, 3, 1, 1, 4, 2, 2, 1, 1, 3, 2, 1,\n",
       "       1, 1, 2, 1, 1, 3, 1, 1, 4, 4, 1, 3, 3, 2, 1, 2, 1, 1, 1, 3, 1, 1,\n",
       "       4, 1, 2, 1, 3, 1, 1, 3, 3, 4, 3, 2, 1, 2, 1, 3, 1, 1, 2, 1, 3, 3,\n",
       "       2, 4, 3, 1, 1, 2, 1, 1, 3, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1,\n",
       "       2, 1, 1, 1, 3, 1, 1, 1, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 3,\n",
       "       3, 1, 1, 2, 2, 3, 2, 1, 1, 2, 3, 1, 3, 2, 1, 2, 1, 4, 3, 4, 1, 1,\n",
       "       1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 3, 1, 1, 1, 1, 1, 3, 2, 2, 2, 1,\n",
       "       3, 1, 1, 1, 1, 3, 2, 3, 1, 2, 3, 1, 1, 2, 1, 1, 2, 3, 1, 4, 1, 2,\n",
       "       1, 1, 1, 2, 1, 2, 2, 3, 3, 1, 1, 1, 3, 4, 1, 1, 2, 1, 1, 3, 3, 3,\n",
       "       3, 2, 1, 1, 1, 4, 3, 2, 2, 2, 2, 1, 2, 4, 4, 1, 2, 1, 3, 1, 3, 2,\n",
       "       1, 5, 1, 1, 2, 5, 1, 1, 2, 2, 1, 1, 2, 1, 3, 1, 1, 3, 2, 4, 3, 4,\n",
       "       1, 2, 1, 2, 4, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 4, 1, 2, 1, 1, 3,\n",
       "       1, 1, 3, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "       3, 1, 2, 1, 2, 2, 3, 1, 4, 2, 3, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 3,\n",
       "       3, 3, 1, 2, 2, 4, 1, 5, 1, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.18556701, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.18556701, 0.18556701,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.35842541, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.35842541, 0.35842541, 0.35842541,\n",
       "       0.18556701, 0.35842541, 0.18556701, 0.35842541, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.35842541, 0.18556701, 0.18556701,\n",
       "       0.18556701, 0.18556701, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.35842541, 0.18556701, 0.18556701, 0.35842541,\n",
       "       0.35842541, 0.18556701, 0.35842541, 0.18556701, 0.35842541])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43movr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC:\u001b[39m\u001b[38;5;124m'\u001b[39m, auc)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/sandbox/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/sandbox/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:634\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multi_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_class must be in (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_multiclass_roc_auc_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    638\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/sandbox/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:706\u001b[0m, in \u001b[0;36m_multiclass_roc_auc_score\u001b[0;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Multiclass roc auc score.\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \n\u001b[1;32m    662\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    703\u001b[0m \n\u001b[1;32m    704\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# validation of the input y_score\u001b[39;00m\n\u001b[0;32m--> 706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(\u001b[38;5;241m1\u001b[39m, \u001b[43my_score\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget scores need to be probabilities for multiclass \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroc_auc, i.e. they should sum up to 1.0 over classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    710\u001b[0m     )\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# validation for multiclass parameter specifications\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/sandbox/lib/python3.10/site-packages/numpy/_core/_methods.py:52\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
